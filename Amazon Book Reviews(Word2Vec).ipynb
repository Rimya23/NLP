{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a2fab9f",
   "metadata": {},
   "source": [
    "### Performing NLP on Amazon's review on books category. The dataset we are using here is a subset of Amazon reviews from the Books category. The data is stored as a csv file and can be read using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9c51e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim as gs\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a88729ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\22000370\\\\Downloads'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8601e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\22000370\\Downloads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55c7cfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\22000370\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (1,2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "book_r=pd.read_csv(r\"C:\\Users\\22000370\\Downloads\\amazondata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c022c512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Helpful Votes (bin)</th>\n",
       "      <th>Number of Records</th>\n",
       "      <th>Star Rating (bin)</th>\n",
       "      <th>Customer Id</th>\n",
       "      <th>Helpful Votes</th>\n",
       "      <th>Overall Votes</th>\n",
       "      <th>Product Id</th>\n",
       "      <th>Review Body</th>\n",
       "      <th>Review Year</th>\n",
       "      <th>Review Headline</th>\n",
       "      <th>Star Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26009102</td>\n",
       "      <td>You will love this book.  It is a hard long re...</td>\n",
       "      <td>03/17/2005 0:00</td>\n",
       "      <td>Best Book Ever</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7491727</td>\n",
       "      <td>This is the UK edition of Dr. Omit's book. Dr....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>researchers from John Hopkins School of Medici...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>002782683X</td>\n",
       "      <td>This is a fun and entertaining book about lear...</td>\n",
       "      <td>06/25/2012 0:00</td>\n",
       "      <td>Michelle</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60187271</td>\n",
       "      <td>Started a big slow, but once into it the autho...</td>\n",
       "      <td>06/09/2013 0:00</td>\n",
       "      <td>Loved the book</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60392452</td>\n",
       "      <td>Received this book as a Christmas present. I h...</td>\n",
       "      <td>08/05/2003 0:00</td>\n",
       "      <td>Challenges your assumptions</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128840</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60529148</td>\n",
       "      <td>John Stossel explains within these pages how h...</td>\n",
       "      <td>05/19/2004 0:00</td>\n",
       "      <td>Heroic</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128841</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60579412</td>\n",
       "      <td>When Bill Clinton said that we were all cold w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the record needed to be set straight.  Mona Ch...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128842</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60184973</td>\n",
       "      <td>During her reign, Queen Mary foiled several pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queen of Scots -- but then</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128843</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7444117</td>\n",
       "      <td>I just don't understand how this was supposed ...</td>\n",
       "      <td>03/26/2014 0:00</td>\n",
       "      <td>So upsetting</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128844</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7337701</td>\n",
       "      <td>No one can explain what seems to be the serend...</td>\n",
       "      <td>09/02/2013 0:00</td>\n",
       "      <td>ultimately real and insightful</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128845 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Helpful Votes (bin) Number of Records Star Rating (bin)  Customer Id  \\\n",
       "0                        0                 1               0.0          NaN   \n",
       "1                      NaN                 1               NaN          NaN   \n",
       "2                        0                 1               0.0          NaN   \n",
       "3                        0                 1               0.0          NaN   \n",
       "4                        0                 1               0.0          NaN   \n",
       "...                    ...               ...               ...          ...   \n",
       "128840                   0                 1                 0          NaN   \n",
       "128841                 NaN                 1               NaN          NaN   \n",
       "128842                 NaN                 1               NaN          NaN   \n",
       "128843                   0                 1                 0          NaN   \n",
       "128844                   0                 1                 0          NaN   \n",
       "\n",
       "        Helpful Votes  Overall Votes  Product Id  \\\n",
       "0                 4.0           14.0    26009102   \n",
       "1                 NaN            NaN     7491727   \n",
       "2                 2.0            2.0  002782683X   \n",
       "3                 0.0            0.0    60187271   \n",
       "4                14.0           20.0    60392452   \n",
       "...               ...            ...         ...   \n",
       "128840            4.0            6.0    60529148   \n",
       "128841            NaN            NaN    60579412   \n",
       "128842            NaN            NaN    60184973   \n",
       "128843            1.0            1.0     7444117   \n",
       "128844            0.0            0.0     7337701   \n",
       "\n",
       "                                              Review Body      Review Year  \\\n",
       "0       You will love this book.  It is a hard long re...  03/17/2005 0:00   \n",
       "1       This is the UK edition of Dr. Omit's book. Dr....              NaN   \n",
       "2       This is a fun and entertaining book about lear...  06/25/2012 0:00   \n",
       "3       Started a big slow, but once into it the autho...  06/09/2013 0:00   \n",
       "4       Received this book as a Christmas present. I h...  08/05/2003 0:00   \n",
       "...                                                   ...              ...   \n",
       "128840  John Stossel explains within these pages how h...  05/19/2004 0:00   \n",
       "128841  When Bill Clinton said that we were all cold w...              NaN   \n",
       "128842  During her reign, Queen Mary foiled several pl...              NaN   \n",
       "128843  I just don't understand how this was supposed ...  03/26/2014 0:00   \n",
       "128844  No one can explain what seems to be the serend...  09/02/2013 0:00   \n",
       "\n",
       "                                          Review Headline  Star Rating  \n",
       "0                                          Best Book Ever          5.0  \n",
       "1       researchers from John Hopkins School of Medici...          NaN  \n",
       "2                                                Michelle          5.0  \n",
       "3                                          Loved the book          5.0  \n",
       "4                             Challenges your assumptions          4.0  \n",
       "...                                                   ...          ...  \n",
       "128840                                             Heroic          4.0  \n",
       "128841  the record needed to be set straight.  Mona Ch...          NaN  \n",
       "128842                         Queen of Scots -- but then          NaN  \n",
       "128843                                       So upsetting          2.0  \n",
       "128844                     ultimately real and insightful          5.0  \n",
       "\n",
       "[128845 rows x 11 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24c078f",
   "metadata": {},
   "source": [
    "### Renaming the Column\n",
    "\n",
    "We only have to work on the Review Body column therefore we only changed this column's naming convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eef928ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_r = book_r.rename(columns={'Review Body': 'Review_Body'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51244cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Helpful Votes (bin)', 'Number of Records', 'Star Rating (bin)',\n",
       "       'Customer Id', 'Helpful Votes', 'Overall Votes', 'Product Id',\n",
       "       'Review_Body', 'Review Year', 'Review Headline', 'Star Rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_r.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c17ff4",
   "metadata": {},
   "source": [
    "# Data Dictionary\n",
    "\n",
    "reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "\n",
    "Number of Records-No.of rows \n",
    "\n",
    "Star Rating (bin) - Ratings given divided in groups\n",
    "\n",
    "CustomerID- Id of the Reviewer\n",
    "\n",
    "Helpful Votes- helpfulness rating of the review, e.g. 2/3\n",
    "\n",
    "Overall Votes - rating of the product\n",
    "\n",
    "Product Id- ID of the product\n",
    "\n",
    "Review Body - text of the review\n",
    "\n",
    "Review_Headline- summarized version of the review\n",
    "\n",
    "ReviewYear - Year when the review was given\n",
    "\n",
    "Star Rating-Ratings by the reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31376891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128845, 11)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6ae1464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 128845 entries, 0 to 128844\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   Helpful Votes (bin)  114947 non-null  object \n",
      " 1   Number of Records    128843 non-null  object \n",
      " 2   Star Rating (bin)    116311 non-null  object \n",
      " 3   Customer Id          59980 non-null   float64\n",
      " 4   Helpful Votes        114943 non-null  float64\n",
      " 5   Overall Votes        116121 non-null  float64\n",
      " 6   Product Id           128840 non-null  object \n",
      " 7   Review_Body          128834 non-null  object \n",
      " 8   Review Year          114933 non-null  object \n",
      " 9   Review Headline      128831 non-null  object \n",
      " 10  Star Rating          116305 non-null  float64\n",
      "dtypes: float64(4), object(7)\n",
      "memory usage: 10.8+ MB\n"
     ]
    }
   ],
   "source": [
    "book_r.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ea98ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Helpful Votes (bin)    13898\n",
       "Number of Records          2\n",
       "Star Rating (bin)      12534\n",
       "Customer Id            68865\n",
       "Helpful Votes          13902\n",
       "Overall Votes          12724\n",
       "Product Id                 5\n",
       "Review_Body               11\n",
       "Review Year            13912\n",
       "Review Headline           14\n",
       "Star Rating            12540\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_r.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ec809e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.headline_text.fillna(\"IGNORE TEXT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d860568",
   "metadata": {},
   "source": [
    "### Dropping the NA Values\n",
    "\n",
    "NA values do not have any role to play for us in the Word2Vec model and thus removing them is a better option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fd66e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = book_r.dropna(subset=['Review_Body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da4db08",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "We need to do a lot of pre-processing before we move on to the modelling step like converting all words to a single case, removing stop words etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "864a311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text=reviews.Review_Body.apply(gs.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc87362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Checking the top 5 rows for us to check the pre-processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa889c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [you, will, love, this, book, it, is, hard, lo...\n",
       "1    [this, is, the, uk, edition, of, dr, omit, boo...\n",
       "2    [this, is, fun, and, entertaining, book, about...\n",
       "3    [started, big, slow, but, once, into, it, the,...\n",
       "4    [received, this, book, as, christmas, present,...\n",
       "Name: Review_Body, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a42821",
   "metadata": {},
   "source": [
    "### Entire result or the tokenized text came in the form of a series.\n",
    "Each object in the series is a list and each list contains a list of tokenized words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20a52016",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=gs.models.Word2Vec(window=10,min_count= 2,workers=4 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "300483d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#window= how many words before the target ex.10(10 words before your target word and 10 after target word)\n",
    "#min_count=If a sentence only has one word don't use that sentence, atleast 2 words are required for the sentence to be considered in the training\n",
    "#workers= how many CPU threads you need to train this model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "014c6d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(review_text,progress_per=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbe961a",
   "metadata": {},
   "source": [
    "The build_vocab() step is how the model discovers the set of all possible words/doc-tags â€“ and in the case of words, finds which words occur more than min_count times.\n",
    "First and foremost, the model needs to know the words present and their frequencies â€“ a working vocabulary â€“ so that it can determine the words that will remain after the min_count floor is applied, and allocate/initialize word-vectors & internal model structures for the relevant words. The word-frequencies will also be used to influence the random sampling of negative-word-examples (for the default negative-sampling mode) and the downsampling of very-frequent words (per the sample parameter).\n",
    "\n",
    "Additionally, the model needs to know the rough size of the overall training set in order to gradually decrement the internal alpha learning-rate over the course of each epoch, and give meaningful progress-estimates in logging output.\n",
    "\n",
    "At the end of build_vocab(), all memory/objects needed for the model have been created. Per the needs of the underlying algorithm, all vectors will have been initialized to low-magnitude random vectors to ready the model for training. (It essentially won't use any more memory, internally, through training.)\n",
    "\n",
    "Also, after build_vocab(), the vocabulary is frozen: any words presented during training (or later inference) that aren't already in the model will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c480560d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f0df0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By default the epochs are set to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86d0c479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128834"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5abe2040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42849560, 56538715)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(review_text,total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9925b0",
   "metadata": {},
   "source": [
    "### This is the training step where our model will go through all the 128834 sentences to prepare the Word2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc814e2c",
   "metadata": {},
   "source": [
    "#### Saving the model(in order to store it in Cloud according to the future requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54b9da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./word2vec-Amazon_Book_Reviews.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960b0360",
   "metadata": {},
   "source": [
    "### Similarity Check as a part of Word2Vec\n",
    "\n",
    "We entered a word interesting and wanted to test our model to check for words which are most similar to interesting and our model gave us the words along with giving us a similarity score too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "680fdb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('intriguing', 0.7801146507263184),\n",
       " ('enjoyable', 0.7178838849067688),\n",
       " ('entertaining', 0.676686704158783),\n",
       " ('exciting', 0.6748363971710205),\n",
       " ('fascinating', 0.6471625566482544),\n",
       " ('engaging', 0.6395599842071533),\n",
       " ('impressive', 0.5981829166412354),\n",
       " ('accurate', 0.5847204923629761),\n",
       " ('amusing', 0.5754761099815369),\n",
       " ('unusual', 0.5723066926002502)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"interesting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104a7dea",
   "metadata": {},
   "source": [
    "### We can check for more such similar words with putting up different words for our model to work on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5064de2",
   "metadata": {},
   "source": [
    "### Similarity score between huge and big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ecd16df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72469556"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"huge\",w2=\"big\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fa8d46",
   "metadata": {},
   "source": [
    "### Therefore, we can check for similarity between more word combinations like these which shows that our model is working nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb35ce4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
